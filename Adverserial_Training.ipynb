{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adverserial Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampath9dasari/GSU/blob/master/Adverserial_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCBeUwVp9AS",
        "colab_type": "text"
      },
      "source": [
        "# Defense with adversarial training\n",
        "\n",
        "In this section we will use adversarial training to harden our CNN against adversarial examples. \n",
        "\n",
        "In adversarial training the dataset get \"augmented\" with adversarial examples that are correctly labeled. This way the network learns that such pertubations are possible and can adapt to them. \n",
        "\n",
        "We will be using the IBM Adversarial Robustness Toolbox in this exercise. It offers a very easy-to-use implementation of adversarial training and a number of other defenses. \n",
        "https://github.com/IBM/adversarial-robustness-toolbox\n",
        "\n",
        "\n",
        "We start out by importing most of the modules and functions we will need. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsvgCPv17t3u",
        "colab_type": "code",
        "outputId": "5b81c821-957d-48bb-9f76-d484cf76ac14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/80/443c8bec5502c6315c9d089d7c8b8050ea337a7da72a957c15e86f013bf8/adversarial_robustness_toolbox-1.1.1-py3-none-any.whl (436kB)\n",
            "\r\u001b[K     |▊                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30kB 7.4MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 440kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (45.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.22.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->adversarial-robustness-toolbox) (0.14.1)\n",
            "Installing collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.1.1\n",
            "Cloning into 'cleverhans'...\n",
            "remote: Enumerating objects: 13469, done.\u001b[K\n",
            "remote: Total 13469 (delta 0), reused 0 (delta 0), pack-reused 13469\u001b[K\n",
            "Receiving objects: 100% (13469/13469), 8.40 MiB | 2.16 MiB/s, done.\n",
            "Resolving deltas: 100% (9473/9473), done.\n",
            "Processing ./cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 9.3MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.1.3)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.17.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans==3.0.1) (45.1.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=252272 sha256=88b7bca5cb781398dc7c8ee7918a6c45e4594fd8ca2646a1b574cdd079e06681\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8jd5pru2/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFCdbXWxp9AU",
        "colab_type": "code",
        "outputId": "8b262f6c-e723-4458-a89a-1288e07fed68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# most of our imports\n",
        "import warnings\n",
        "import numpy as np\n",
        "import os\n",
        "with warnings.catch_warnings():\n",
        "    import keras # keras is still using some deprectade code\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "from cleverhans.attacks import BasicIterativeMethod, FastGradientMethod, CarliniWagnerL2\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from art.classifiers import KerasClassifier\n",
        "\n",
        "\n",
        "# helper code \n",
        "def exract_ones_and_zeroes( data, labels ):\n",
        "    data_zeroes = data[ np.argwhere( labels == 0 ).reshape( -1 ) ][ :200 ]\n",
        "    data_ones = data[ np.argwhere( labels == 1 ).reshape( -1 ) ][ :200 ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "\n",
        "    x = x / 255.\n",
        "    print( x.shape )\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def exract_two_classes( data, labels, classes=(0,1), no_instance=200 ):\n",
        "    data_zeroes = data[ np.argwhere( labels ==  classes[0] ).reshape( -1 ) ][ :no_instance ]\n",
        "    data_ones = data[ np.argwhere( labels == classes[1] ).reshape( -1 ) ][ :no_instance ]\n",
        "    x = np.vstack( (data_zeroes, data_ones) )\n",
        "    \n",
        "    # normalize the data\n",
        "    x = x / 255.\n",
        "\n",
        "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
        "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
        "    y = np.append( labels_zeroes, labels_ones )\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def convert_to_keras_image_format( x_train, x_test ):\n",
        "    if keras.backend.image_data_format( ) == 'channels_first':\n",
        "        x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "        x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
        "    else:\n",
        "        x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "        x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
        "\n",
        "    return x_train, x_test\n",
        "\n",
        "\n",
        "def mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=2 ):\n",
        "    # define the classifier\n",
        "    clf = keras.Sequential( )\n",
        "    clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
        "    clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
        "    clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
        "    clf.add( Dropout( 0.25 ) )\n",
        "    clf.add( Flatten( ) )\n",
        "    clf.add( Dense( 128, activation='relu' ) )\n",
        "    clf.add( Dropout( 0.5 ) )\n",
        "    clf.add( Dense( y_train.shape[ 1 ], activation='softmax' ) )\n",
        "\n",
        "    clf.compile( loss=keras.losses.categorical_crossentropy,\n",
        "                 optimizer='adam',\n",
        "                 metrics=[ 'accuracy' ] )\n",
        "\n",
        "    clf.fit( x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             verbose=1 )\n",
        "    clf.summary( )\n",
        "    score = clf.evaluate( x_test, y_test )\n",
        "    print( 'Test loss:', score[ 0 ] )\n",
        "    print( 'Test accuracy:', score[ 1 ] )\n",
        "\n",
        "    return clf\n",
        "\n",
        "\n",
        "def show_image( img ):\n",
        "    plt.imshow( img.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "    plt.axis( 'off' )\n",
        "    plt.show( )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/utils_tf.py:345: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQb51r9Pp9AY",
        "colab_type": "text"
      },
      "source": [
        "We start out by loading the data, preparing it and training our CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi_KR9mVp9AZ",
        "colab_type": "code",
        "outputId": "6428565d-7c3d-4411-b347-c7f68f605d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
        "x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n",
        "\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "\n",
        "# need to some setup so everything gets excturted in the same tensorflow session\n",
        "session = tf.Session( )\n",
        "keras.backend.set_session( session )\n",
        "\n",
        "# get and train our cnn\n",
        "clf = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(400, 28, 28)\n",
            "(400, 28, 28)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "400/400 [==============================] - 14s 34ms/step - loss: 0.1635 - acc: 0.9375\n",
            "Epoch 2/5\n",
            "400/400 [==============================] - 0s 235us/step - loss: 0.0308 - acc: 0.9900\n",
            "Epoch 3/5\n",
            "400/400 [==============================] - 0s 192us/step - loss: 0.0254 - acc: 0.9950\n",
            "Epoch 4/5\n",
            "400/400 [==============================] - 0s 206us/step - loss: 0.0253 - acc: 0.9925\n",
            "Epoch 5/5\n",
            "400/400 [==============================] - 0s 211us/step - loss: 0.0112 - acc: 0.9975\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,198,850\n",
            "Trainable params: 1,198,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "400/400 [==============================] - 0s 238us/step\n",
            "Test loss: 0.001428274830104783\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No-xgwJAp9Ae",
        "colab_type": "text"
      },
      "source": [
        "We want to know how robust our model is against an attack. To do this we are calculating the `empirical robustness`. This is equivalent to computing the minimal perturbation that the attacker must introduce for a    successful attack. We are following the approach of Moosavi-Dezfooli et al. 2016 (paper link: https://arxiv.org/abs/1511.04599).\n",
        "\n",
        "The emperical robustness method supports two attacks at the moment. \n",
        "The `Fast Gradient Sign Method` and `Hop Skip and Jump`.\n",
        "\n",
        "You can use them by passing either `fgsm` or `hsj` as parameters.\n",
        "The default attack parameters are the following:\n",
        "```\n",
        "    \"fgsm\":{\"eps_step\": 0.1, \"eps_max\": 1., \"clip_min\": 0., \"clip_max\": 1.},\n",
        "    \"hsj\" {'max_iter': 50, 'max_eval': 10000, 'init_eval': 100, 'init_size': 100}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGO_xXwHp9Af",
        "colab_type": "code",
        "outputId": "0a1b8a60-5478-4c40-e966-b139507e34b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from art.metrics import empirical_robustness\n",
        "\n",
        "# wrap the model an calculte emperical robustnees\n",
        "wrapper = KerasClassifier( model=clf, clip_values=(0., 1.) )\n",
        "print( 'robustness of the undefended model', \n",
        "      empirical_robustness( wrapper, x_test, 'fgsm'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "robustness of the undefended model 0.19556192131066377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHoKCGrJWtIy",
        "colab_type": "text"
      },
      "source": [
        "Try different attack parameters and compare the results. \n",
        "\n",
        "Tip:\n",
        "\n",
        "For `hsj` use only a few examples otherwise it will take forever."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNgpmoIWNTV",
        "colab_type": "code",
        "outputId": "961dccd7-b6e9-4599-c0b4-8515768829e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "### your code goes here\n",
        "x_small = x_test[ :10 ]\n",
        "print( 'robustness for hsj', \n",
        "      empirical_robustness( wrapper, x_small, 'hsj'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-76b8fdf49578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print( 'robustness for hsj', \n\u001b[0;32m----> 3\u001b[0;31m       empirical_robustness( wrapper, x_small, 'hsj'))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/metrics/metrics.py\u001b[0m in \u001b[0;36mempirical_robustness\u001b[0;34m(classifier, x, attack_name, attack_params)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mcrafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_crafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mcrafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'minimal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Predict the labels for adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/evasion/hop_skip_jump.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 x_adv[ind] = self._perturb(x=val, y=-1, y_p=preds[ind], init_pred=init_preds[ind],\n\u001b[0;32m--> 148\u001b[0;31m                                            adv_init=x_adv_init[ind], clip_min=clip_min, clip_max=clip_max)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/evasion/hop_skip_jump.py\u001b[0m in \u001b[0;36m_perturb\u001b[0;34m(self, x, y, y_p, init_pred, adv_init, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# If an initial adversarial example found, then go with hopskipjump attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/evasion/hop_skip_jump.py\u001b[0m in \u001b[0;36m_attack\u001b[0;34m(self, initial_sample, original_sample, target, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mnum_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_eval\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_iter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             update = self._compute_update(current_sample=current_sample, num_eval=num_eval, delta=delta,\n\u001b[0;32m--> 298\u001b[0;31m                                           target=target, clip_min=clip_min, clip_max=clip_max)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;31m# Finally run step size search by first computing epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/evasion/hop_skip_jump.py\u001b[0m in \u001b[0;36m_compute_update\u001b[0;34m(self, current_sample, num_eval, delta, target, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# implemented in the original source code of the authors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         satisfied = self._adversarial_satisfactory(samples=eval_samples, target=target,\n\u001b[0;32m--> 441\u001b[0;31m                                                    clip_min=clip_min, clip_max=clip_max)\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msatisfied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_eval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mART_NUMPY_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/evasion/hop_skip_jump.py\u001b[0m in \u001b[0;36m_adversarial_satisfactory\u001b[0;34m(self, samples, target, clip_min, clip_max)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[1;32m    476\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/classifiers/keras.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81zo5QTEuMs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( 'robustness for fgsm2', \n",
        "  empirical_robustness(wrapper, x_test, \"fgsm\",{\"eps_step\": 0.3, \"eps_max\": 1., \"clip_min\": 0., \"clip_max\": 1.}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkJT6D_p9Ai",
        "colab_type": "text"
      },
      "source": [
        "Let's create an adversarial example and see how it looks.\n",
        "We want to know how to the model performs on adversarial exampels. Let's create adversarial examples out of the training set and see how the model does with it.\n",
        "\n",
        "Below you can the keyword arguments for the attack\n",
        "\n",
        "```\n",
        "norm=np.inf, eps=.3, eps_step=0.1, targeted=False, num_random_init=0, batch_size=1, minimal=False\n",
        "        \"\"\"\n",
        "        :param norm: The norm of the adversarial perturbation. Possible values: np.inf, 1 or 2.\n",
        "        :param eps: Attack step size (input variation)\n",
        "        :param eps_step: Step size of input variation for minimal perturbation computation\n",
        "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False)\n",
        "        :param num_random_init: Number of random initialisations within the epsilon ball. For random_init=0 starting at\n",
        "            the original input.\n",
        "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
        "        :param minimal: Indicates if computing the minimal perturbation (True). If True, also define `eps_step` for\n",
        "                        the step size and eps for the maximum perturbation.\n",
        "   \n",
        "```\n",
        "\n",
        "Find good parameters for the attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w2jwVnLzNOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.zeros(x_test.shape).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-anGrCjjp9Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an adversarial example with fgsm and plot it\n",
        "from art.attacks import FastGradientMethod\n",
        "fgsm = FastGradientMethod( wrapper, eps=0.3 )\n",
        "x_adv = fgsm.generate( x_test[ 0 ].reshape( (1,28,28,1) ) )\n",
        "# prediction for the adversarial example\n",
        "print(clf.predict(x_adv))\n",
        "# show the adverarial example\n",
        "show_image( x_adv )\n",
        "\n",
        "# x_test_adv = np.zeros(x_test.shape)\n",
        "# create adversarial examples for the all of the set\n",
        "# for i in range(len(x_test)):\n",
        "x_test_adv = fgsm.generate( x_test )\n",
        "clf.evaluate(x_test_adv,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhEY7Iagp9Aw",
        "colab_type": "text"
      },
      "source": [
        "## Adversarial Training\n",
        "\n",
        "Let's create a new untrained model with the same architecture that we have been using so far. \n",
        "\n",
        "We will train the model using adversarial training framework. The idea is very simple:\n",
        "\n",
        "1.   Train the model for 1 epoch\n",
        "2.   Create adversarial examples using FGSM \n",
        "3.   Enhance training data by mixing it with the adversarial examples. (Only mix in the adversarial examples created in this iteartion)\n",
        "4.   Goto 1\n",
        "\n",
        "We will be using the FGSM attack from `art` this time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHrX6WftGOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new untrained model and wrap it\n",
        "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
        "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( defended_model, eps=.3 )\n",
        "\n",
        "# parameters\n",
        "epochs = 5 # number of iterations that we will perform training for\n",
        "ratio = .5  # ratio of the test set that will get turned into adversarial examples\n",
        "            # each iteration\n",
        "\n",
        "\n",
        "# some helpers\n",
        "idx = np.arange( x_train.shape[ 0 ], dtype=np.int )\n",
        "\n",
        "# create varialbes to hold the training data.\n",
        "# for now it is just the normal training data. we'll mix in the \n",
        "# adversarial examples in later\n",
        "x_train_enhanced = x_train\n",
        "y_train_enhanced = y_train\n",
        "\n",
        "\n",
        "for i in range( epochs ):\n",
        "  # train model for one epoch\n",
        "  new_model.fit(x_train_enhanced,y_train_enhanced)\n",
        "\n",
        "  # shuffle   \n",
        "  np.random.shuffle(idx)\n",
        "\n",
        "  # pick the subest of the train data to turn into adverarial examples\n",
        "  x_sub = x_train[idx[:100]]\n",
        "  y_sub = y_train[idx[:100]]\n",
        "\n",
        "\n",
        "  # create adversarial examples\n",
        "  x_sub_adv = fgsm.generate( x_sub )\n",
        "\n",
        "  # add the adversarial examples to the training data\n",
        "  x_train_enhanced = np.append(x_train,x_sub_adv,axis=0)\n",
        "  y_train_enhanced = np.append(y_train,y_sub,axis=0)\n",
        "\n",
        "# training is done. let's evaulate the performance on the test set \n",
        "# and adversarial examples\n",
        "acc = defended_model._model.evaluate( x_test, y_test )[ 1 ]\n",
        "print( 'acc on the test data: ', acc )\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = fgsm.generate( x_test )\n",
        "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
        "print( 'accuracy on adversarial examples: ', acc )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhTCRfbCr6iq",
        "colab_type": "text"
      },
      "source": [
        "To use the adversarial training that comes with `art` we need to pass our wrapped model to an `AdversarialTrainer` instance. The `AdversarialTrainer` also needs an instance of the attack that will be used to create the adversarial examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxQZLbgBp9Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from art.defences import AdversarialTrainer\n",
        "\n",
        "# get a new untrained model and warp it\n",
        "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
        "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( defended_model )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3geBOs1p9A4",
        "colab_type": "text"
      },
      "source": [
        "Create the `AdversarialTrainer` instance. \n",
        "Train the model and evaluate it on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BWvgxNtp9A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the adversarial trainer and train the new network\n",
        "adversarial_tranier = AdversarialTrainer( defended_model, fgsm )\n",
        "adversarial_tranier.fit( x_train, y_train, batch_size=100, nb_epochs=5 )\n",
        "\n",
        "# evaluate how good our model is\n",
        "defended_model._model.evaluate( x_test,y_test )\n",
        "\n",
        "# and now on adversarial examples\n",
        "x_test_adv = fgsm.generate( x_test )\n",
        "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
        "print( 'accuracy on adversarial examples: ', acc )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV0kBz2Fp9BA",
        "colab_type": "text"
      },
      "source": [
        "Calculate the `empirical robustness` for our now hopefully more robust model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7CROH1Gp9BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the empiracal robustness\n",
        "print( 'robustness of the defended model', \n",
        "      empirical_robustness( defended_model, x_test[0:], 'fgsm', {}) )\n",
        "x_adv = fgsm.generate(x_test[0].reshape((1,28,28,1) ))\n",
        "print( 'class prediction for the adversarial sample:',\n",
        "       clf.predict( x_adv.reshape((1,28,28,1) ) ) \n",
        "     )\n",
        "plt.imshow( x_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPL9ywQnKu2w",
        "colab_type": "text"
      },
      "source": [
        "# Defensive Distillation\n",
        "\n",
        "The idea behind defensive distiallation is to transfere robustness from one network to another. To do this we are training two networks. The first network, which we will call `one` is trained normally. We want to transfer some of the *experience* to our second network, called `two`. Both `one` and `two` have the same architecture. The way we achieve is this is by training `two` with the ouputs of `one`. An important change is that we are using a so called *temperature* `T` parameter in the softmax function.\n",
        "The process is as follows:\n",
        "\n",
        "\n",
        "1.   Train `one` at temprature `T`\n",
        "2.   Create new labels for the training data using `one`\n",
        "3.   Train `two` at temprature `T` using the new labels\n",
        "\n",
        "\n",
        "Hints:\n",
        "\n",
        "\n",
        "*   `tf.math.exp`\n",
        "*   `keras.backend.in_train_phase`\n",
        "*   kullback leibler divergence\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHdXvFx1Sud0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# softmax with temprature\n",
        "T = 10\n",
        "\n",
        "\n",
        "# define the classifier one\n",
        "\n",
        "\n",
        "# test the FGSM attack\n",
        "\n",
        "\n",
        "# create new labels\n",
        "\n",
        "\n",
        "# define the classifier two\n",
        "\n",
        "\n",
        "# test the FGSM attack\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d2J443nA9k8",
        "colab_type": "text"
      },
      "source": [
        "# Black box attacks\n",
        "\n",
        "Assume we do not have access to the internal workings of our target model. This means we can not easily calculate gradients.\n",
        "Fortunatley or unfortunatle depending on how you are looking at it adversarial exampels created on one model can be also used against a different model. Given their learned descion boundary is similar enough. \n",
        "\n",
        "We do not know what the target model looks like but in most cases we no the domain that it works in, MNIST in our case, so we can make an educated guess. We then train our model with the architecture that we guessed and create adversarial examples using this model. If our model and the target model are similare enough the adversarial examples can be transferd.\n",
        "\n",
        "\n",
        "In the code below we will be training two different models and see if the adversarial examples transfer from one to the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay5X8686uwA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras.backend as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Reshape\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
        "x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n",
        "\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "\n",
        "# Create simple CNN\n",
        "model_0 = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5 )\n",
        "print( model_0.evaluate( x_test, y_test )[ 1 ] )\n",
        "# create a simple DNN and train it\n",
        "\n",
        "\n",
        "# compare how the models do on the test set\n",
        "\n",
        "\n",
        "\n",
        "# compare how the models perform on adversarial examples\n",
        "\n",
        "\n",
        "\n",
        "# let's see how the models do when we give them the adversarial examples \n",
        "# created against the other model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzIPPxrxOKFA",
        "colab_type": "text"
      },
      "source": [
        "We do not always have access to the same training data though. We can collect our own data and use the victim model to label the data. \n",
        "\n",
        "Using `model_0` from the cell above as the victim model in a black box setting train you own substitue model on the training data provided in the cell below. Pick an architecture that you think will work well or that you are interested in trying. The paper desrcibing the attack can be found here: https://arxiv.org/abs/1602.02697\n",
        "\n",
        "Hint: `cleverhans` provides a few helpful functions for performing the data augmentation.\n",
        "\n",
        " Also try the transferability of attacks other than FGSM. Hint: Don't use the too much data for more complex attacks or it will take a long time. Start with a smaller subset first to get a feeling how long it takes to generate advesarial examples.\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNXPkTWLRi1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up black box. should already be trained. if not run the cell above first.\n",
        "black_box = model_0\n",
        "\n",
        "# load data that is differen from the data that black box has been trained on.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# extract ones and zeroes\n",
        "x_train, y_train = exract_two_classes( x_train, y_train, no_instance=400 )\n",
        "x_test, y_test = exract_two_classes( x_test, y_test, no_instance=400 )\n",
        "\n",
        "# pick few instances from the training data\n",
        "x_train = x_train[ [0,1, 199, 200] ]\n",
        "y_train = y_train[ [0,1, 199, 200] ]\n",
        "# we need to bring the data in to a format that our cnn likes\n",
        "y_train = keras.utils.to_categorical( y_train, 2 )\n",
        "y_test = keras.utils.to_categorical( y_test, 2 )\n",
        "print( x_train.shape )\n",
        "# convert it to a format keras can work with\n",
        "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
        "print( x_train.shape )\n",
        "\n",
        "# use the black box classifier to create labes for the training data\n",
        "\n",
        "# define subsitute model\n",
        "\n",
        "# create computational graph for data augmentation\n",
        "\n",
        "# train your own substitute  model\n",
        "\n",
        "  # train for a few epochs\n",
        "\n",
        "  # perform data augmentation\n",
        "\n",
        "    # get labels for new data\n",
        "\n",
        "\n",
        "# create adverasarial examples on the substitute model\n",
        "sub_wrapper = KerasClassifier(clip_values=(0,1), model=sub )\n",
        "# define the attack we are using\n",
        "fgsm = FastGradientMethod( sub )\n",
        "x_adv = fgsm.generate( x_test )\n",
        "\n",
        "# evaluate performance on adversarial exampales for the substitute model and the black box\n",
        "black_box.evaluate( x_adv, y_test )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}